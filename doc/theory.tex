\chapter{theory of operation \label{theory}}

The Vision Egg can coordinate just about any task that is possible
with a computer.  This document is a high level overview of how the
Vision Egg works.

If you need triggering of visual stimuli or trigging of external
hardware, data acquisition, precise temporal control of stimuli,
integration with other software or hardware, read this document first.

\section{Architecture}

The Vision Egg is more than a simple library for drawing visual
stimuli. The Vision Egg allows coordination with just about any
element of a computer or connected hardware.  This is acheived via a
main loop that acts as an accurate experimental time-keeper and
delegates commands scheduled for execution.  These commands can return
a value which can be used to control stimuli in real-time, or used for
other things. For specialized functions, you can write adapter code
using Python and/or C.

To perform this role, the Vision Egg uses a paradigm in which
\strong{contollers} can modify any \strong{parameter}. Controllers are
defined by \class{Controller}, and parameters exist in
classes that are derived from \class{ClassWithParameters}.

The \seealso{API reference} has more extensive documentation for the
\class{Presentation}, \class{Controller}, and
\class{ClassWithParameters} classes.

\section{Timing of stimulus display}

Discuss concepts of \class{Presentation} class.

The main loop can execute in one of two modes.  In the usual
\strong{frame sync mode}, the completion of each cycle is delayed
until the \crossref{vertical retrace sync signal}. This allows precise
frame by frame control of stimuli, but may be more subject to
completely skipping a frame.  \strong{Fast cycle mode} can be used to
benchmark the performance of a system, to perform tasks as quickly as
possible, or because frame-locked mode is not available.

\section{Triggering}

\strong{Triggering external hardware} from the Vision Egg can be done in
several ways. For the ultimate in temporal precision, ``arm'' the
trigger immediately before the vertical sync pulse of the video frame
of interest. This can be done via a data acquisition device, a
software command, or a parallel port pin. Then tap into the vertical
sync pin of your video cable, and use this as the trigger. For easier,
but less temporally precise triggering of external hardware, use any
of these methods as the trigger itself.  In this case the accuracy
could be no better than the inter-frame interval.

\strong{Triggering the Vision Egg} This is not implemented yet. I don't
think temporal precision can be better than the inter-frame
interval. First will be triggering based on using the parallel port as
input, but may not work for fast (non-holding) triggers.

\section{Data acquisition}

\section{Stimulus drawing}