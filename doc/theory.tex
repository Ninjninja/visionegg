\chapter{theory of operation \label{theory}}

Note: This documentation is very incomplete.  If this does not cover
your needs, read the reference documentation, which is contained in
the source code, but can be extracted automatcally by pydoc, for
example.  (Try running ``pydoc'' from the command line of your
system. Or look at the source code itself.)

The Vision Egg can coordinate just about any task that is possible
with a computer.  This document is a high level overview of how the
Vision Egg works and what tasks are currently incorporated into the
Vision Egg.

If you need to perform tasks such as triggering of visual stimuli or
external hardware, data acquisition, control with precise timing
stimuli or other computer software or hardware, or integrate with
other software or hardware, read this document to gain an
understanding of how all the pieces fit together.

\section{Overall Architecture}

The Vision Egg is more than a simple library for drawing visual
stimuli. The Vision Egg allows coordination with just about any
element of a computer or connected hardware.  This is acheived via a
main ``go'' loop that acts as an accurate experimental time-keeper and
delegates commands scheduled for execution.  These commands can return
a value which can be used to control stimuli in real-time, or used for
other things. For specialized functions, you can write adapter code
using Python and/or C.

To perform this role, the Vision Egg uses a paradigm in which
\strong{contollers} can modify any \strong{parameter}. Controllers are
defined by \class{Controller}, and parameters exist in classes that
are derived from \class{ClassWithParameters}.

The \seealso{interface reference} has more extensive documentation for
the \class{Presentation}, \class{Controller}, and
\class{ClassWithParameters} classes.

\section{Timing of stimulus display}

Concepts of \class{Presentation} class:

The activity of controllers and their parameters is coordinated by
\class{Presentation}, which has two ways in which it operates.  First
is the ``go'' loop.  Second is an additional set of coordination that
happens when the go loop is not evaluating. In an experimental
situation, the VisionEgg is typically placed in a ``run forever''
mode, which is able to run go loops as necessary.  The run forever
mode maintains the stimuli and parameters/controllers while waiting to
enter a go loop, although useful things may be accomplished without
entering a go loop.  In an experimental situation, however, the go
loop provides precise timing from its onset, and is therefore very
useful to display a stimulus for exactly 5 seconds, for example.

The main ``go'' loop can execute in one of two modes.  In the usual
\strong{frame sync mode}, the completion of each cycle is delayed
until the \crossref{vertical retrace sync signal}. This allows precise
frame by frame control of stimuli, but may be more subject to
completely skipping a frame.  \strong{Fast cycle mode} can be used to
benchmark the performance of a system, to perform tasks as quickly as
possible, or because frame-locked mode is not available. In release
0.9.1, automatic designation of mode is not performed.  Instead, the
Vision Egg always attempts to operate in a frame synced mode and gives
a warning if it cannot.

\section{Triggering}

\strong{Triggering external hardware} from the Vision Egg can be done in
several ways. For the ultimate in temporal precision, ``arm'' the
trigger immediately before the vertical sync pulse of the video frame
of interest. This can be done via a data acquisition device, a
software command, or a parallel port pin. Then tap into the vertical
sync pin of your video cable, and use this as the trigger. For easier,
but less temporally precise triggering of external hardware, use any
of these methods as the trigger itself.  In this case the accuracy
could be no better than the inter-frame interval.

Relevant modules: Daq, DaqLPT.  Relevant demos:
demos/daq/trigger_out.py, demos/daq/trigger_in.py.

\strong{Triggering the Vision Egg} Incomplete: How to use
\parameter{enter_go_loop} when in run forever mode.

\section{Data acquisition}

Currently best implemented on other hardware using triggering methods
discussed above.  Can be remotely controlled from remote hardware via
a number of means, easiest probably being TCPController stuff.

\section{Stimulus drawing}

Several stimulus classes are bundled with the Vision Egg.  These all
operate by calling OpenGL to draw some object.  The entire operation
is performed in realtime, meaning that no pre-computed image cache is
made beforehand.  Instead, you define controllers that control aspects
of your stimulus (contrast, for example), which then control the
appearance by recomputing the display on every frame.
